<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>200604文献阅读</title>
  <meta name="description" content="200604文献阅读" />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="200604文献阅读" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="200604文献阅读" />
  
  
  

<meta name="author" content="高文欣" />


<meta name="date" content="2020-06-08" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  


<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="libs/pagedtable-1.1/js/pagedtable.js"></script>



</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path=""><a href="#文献整理"><i class="fa fa-check"></i><b>1</b> 文献整理</a><ul>
<li class="chapter" data-level="1.1" data-path=""><a href="#relation-classiﬁcation-via-convolutional-deep-neural-network"><i class="fa fa-check"></i><b>1.1</b> Relation Classiﬁcation via Convolutional Deep Neural Network</a><ul>
<li class="chapter" data-level="1.1.1" data-path=""><a href="#方法"><i class="fa fa-check"></i><b>1.1.1</b> 方法</a></li>
<li class="chapter" data-level="1.1.2" data-path=""><a href="#参数"><i class="fa fa-check"></i><b>1.1.2</b> 参数</a></li>
<li class="chapter" data-level="1.1.3" data-path=""><a href="#结果"><i class="fa fa-check"></i><b>1.1.3</b> 结果</a></li>
<li class="chapter" data-level="1.1.4" data-path=""><a href="#总结"><i class="fa fa-check"></i><b>1.1.4</b> 总结</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path=""><a href="#attention-based-bidirectional-long-short-term-memory-networks-for-relation-classiﬁcation"><i class="fa fa-check"></i><b>1.2</b> Attention-Based Bidirectional Long Short-Term Memory Networks for Relation Classiﬁcation</a><ul>
<li class="chapter" data-level="1.2.1" data-path=""><a href="#方法-1"><i class="fa fa-check"></i><b>1.2.1</b> 方法</a></li>
<li class="chapter" data-level="1.2.2" data-path=""><a href="#position-indicators"><i class="fa fa-check"></i><b>1.2.2</b> Position Indicators</a></li>
<li class="chapter" data-level="1.2.3" data-path=""><a href="#实验结果"><i class="fa fa-check"></i><b>1.2.3</b> 实验结果</a></li>
<li class="chapter" data-level="1.2.4" data-path=""><a href="#总结-1"><i class="fa fa-check"></i><b>1.2.4</b> 总结</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path=""><a href="#joint-entity-recognition-and-relation-extraction-as-a-multi-head-selection-problem"><i class="fa fa-check"></i><b>1.3</b> Joint entity recognition and relation extraction as a multi-head selection problem</a><ul>
<li class="chapter" data-level="1.3.1" data-path=""><a href="#实体识别模型"><i class="fa fa-check"></i><b>1.3.1</b> 实体识别模型</a></li>
<li class="chapter" data-level="1.3.2" data-path=""><a href="#多头关系抽取模型"><i class="fa fa-check"></i><b>1.3.2</b> 多头关系抽取模型</a></li>
<li class="chapter" data-level="1.3.3" data-path=""><a href="#代码数据"><i class="fa fa-check"></i><b>1.3.3</b> 代码数据</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path=""><a href="#adversarial-training-for-multi-context-joint-entity-and-relation-extraction"><i class="fa fa-check"></i><b>1.4</b> Adversarial training for multi-context joint entity and relation extraction</a><ul>
<li class="chapter" data-level="1.4.1" data-path=""><a href="#相关工作"><i class="fa fa-check"></i><b>1.4.1</b> 相关工作</a></li>
<li class="chapter" data-level="1.4.2" data-path=""><a href="#创新点"><i class="fa fa-check"></i><b>1.4.2</b> 创新点</a></li>
<li class="chapter" data-level="1.4.3" data-path=""><a href="#at"><i class="fa fa-check"></i><b>1.4.3</b> AT</a></li>
<li class="chapter" data-level="1.4.4" data-path=""><a href="#实验结果-1"><i class="fa fa-check"></i><b>1.4.4</b> 实验结果</a></li>
<li class="chapter" data-level="1.4.5" data-path=""><a href="#代码数据-1"><i class="fa fa-check"></i><b>1.4.5</b> 代码数据</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path=""><a href="#entity-relation-extraction-as-multi-turn-question-answering"><i class="fa fa-check"></i><b>1.5</b> Entity-Relation Extraction as Multi-turn Question Answering</a><ul>
<li class="chapter" data-level="1.5.1" data-path=""><a href="#头实体抽取阶段和关系和尾部抽取阶段"><i class="fa fa-check"></i><b>1.5.1</b> 头实体抽取阶段和关系和尾部抽取阶段</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path=""><a href="#基于dgcnn和概率图的轻量级信息抽取模型"><i class="fa fa-check"></i><b>1.6</b> 基于DGCNN和概率图的轻量级信息抽取模型</a></li>
<li class="chapter" data-level="" data-path=""><a href="#参考文献"><i class="fa fa-check"></i>参考文献</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">200604文献阅读</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title">200604文献阅读</h1>
<p class="author"><em>高文欣</em></p>
<p class="date"><em>2020-06-08</em></p>
</div>
<div id="文献整理" class="section level1">
<h1><span class="header-section-number">1</span> 文献整理</h1>
<blockquote>
<p>信息抽取的定义为：从自然语言文本中抽取指定类型的实体、关系、事件等事实信息，并形成结构化数据输出的文本处理技术。信息抽取是从文本数据中抽取特定信息的一种技术。文本数据是由一些具体的单位构成的，例如句子、段落、篇章，文本信息正是由一些小的具体的单位构成的，例如字、词、词组、句子、段落或是这些具体的单位的组合。抽取文本数据中的名词短语、人名、地名等都是文本信息抽取，当然，文本信息抽取技术所抽取的信息可以是各种类型的信息。</p>
</blockquote>
<div id="relation-classiﬁcation-via-convolutional-deep-neural-network" class="section level2">
<h2><span class="header-section-number">1.1</span> Relation Classiﬁcation via Convolutional Deep Neural Network</h2>
<div id="方法" class="section level3">
<h3><span class="header-section-number">1.1.1</span> 方法</h3>
<blockquote>
<p>In this paper, we exploit a convolutional deep neural network(DNN) to extract lexical and sentence level features. Our method takes all of the word tokens as input without complicated pre-processing. First, the word tokens are transformed to vectors by looking up word embeddings1. Then, lexical level features are extracted according to the given nouns. Meanwhile, sentence level features are learned using a convolutional approach. These two level features are concatenated to form the ﬁnal extracted feature vector. Finally, the features are fed into a softmax classiﬁer to predict the relationship between two marked nouns. <span class="citation">(Zeng 2014)</span></p>
</blockquote>
<p>利用卷积深度神经网络（DNN）来提取<strong>词汇</strong>和<strong>句子级别</strong>的特征。</p>
<ul>
<li>预训练好的wordembedding</li>
<li>senstence level提取特征</li>
</ul>
<p>连接这两个级别的特征以形成最终提取的特征向量。最后，将这些特征输入softmax分类器以预测两个标记名词之间的关系。具体如下</p>
<ul>
<li>Word Representation</li>
</ul>
<p>使用预训练好的word embedding作为Word Representation。</p>
<ul>
<li>Lexical Level Features</li>
</ul>
<p>使用通用词嵌入作为基本特征的来源。选择标记名词的嵌入和上下文标记。所有这些功能都连接到词汇级别特征向量。从五个词法层面对句子进行特征提取，来使得我们的模型更加的有偏重性。</p>
<ul>
<li>Sentence Level Features</li>
</ul>
<p>词嵌入技术已经能很好的表达词语之间的相关性。但是不能很好的捕捉远距离的词汇之间的关系，不能让计算机对于一个很长的句子表达有正确的理解。因此我们在句子级别的特征提取中使用卷积神经网络，希望能够结合所有的局部特征、提取句子中远距离的语法信息，最后生成我们的句子级别的特征向量。</p>
<p>本文将输入CNN的token进一步细分为Word Features (WF)和 Position Features
(PF)，其中WF通过设置窗口来在原始单词组成的捕捉句子中某一词语局部的上下文信息，实验决定3是最优窗口大小。</p>
<p>本文还引入了PF，这个是句子中的词语和目标词之间的左右相对距离：</p>
<ul>
<li>CNN</li>
</ul>
<p>前面提取到的都是局部特征，通过CNN提取更加长更加全面的特征。这里的CNN只是简单的<strong>两个隐层</strong>的CNN，使用tanh作为非线性变换函数。</p>
<ul>
<li>softmax分类</li>
</ul>
<p>将CNN输出的全局特征与sentence级别的局部词语表示结合作为输入：f=[l,g]，输出的是一个向量，指明每个分类的概率大小。</p>
</div>
<div id="参数" class="section level3">
<h3><span class="header-section-number">1.1.2</span> 参数</h3>
<div class="figure">
<img src="figs/cnn-para.png" alt="" />
<p class="caption">cnn-para</p>
</div>
</div>
<div id="结果" class="section level3">
<h3><span class="header-section-number">1.1.3</span> 结果</h3>
<p>评价指标:F1</p>
<div class="figure">
<img src="figs/CNN-RE.png" alt="" />
<p class="caption">cnn-re</p>
</div>
</div>
<div id="总结" class="section level3">
<h3><span class="header-section-number">1.1.4</span> 总结</h3>
<ul>
<li><p>使用词法和句子两大类特征，然后将两大类特征拼接到一起，最后接全连接层+softmax得到分类结果。</p></li>
<li><p>嵌入层使用了预训练的词向量，而不是随机初始化，不过用的不是word2vec，而是(Turian 2010 Word representations: a simple and general method for semi-supervised learning)提供的词嵌入。</p></li>
<li><p>加入了Position Feature，因为CNN更多强调的是局部信息，而Position Feature强调了实体信息。</p></li>
</ul>
<blockquote>
<p>We conduct experiments using the SemEval-2010 Task 8 dataset.<span class="citation">(Zeng 2014)</span></p>
</blockquote>
<p>使用SemEval 2010 Task 8 Dataset的数据集，考虑方向共19种关系</p>
<p>数据&amp;代码见:<a href="https://github.com/FrankWork/conv_relation" class="uri">https://github.com/FrankWork/conv_relation</a></p>
<p>或者这个：<a href="https://blog.csdn.net/herosunly/article/details/90145218" class="uri">https://blog.csdn.net/herosunly/article/details/90145218</a></p>
</div>
</div>
<div id="attention-based-bidirectional-long-short-term-memory-networks-for-relation-classiﬁcation" class="section level2">
<h2><span class="header-section-number">1.2</span> Attention-Based Bidirectional Long Short-Term Memory Networks for Relation Classiﬁcation</h2>
<div id="方法-1" class="section level3">
<h3><span class="header-section-number">1.2.1</span> 方法</h3>
<blockquote>
<p>To tackle these problems,we propose Attention-Based Bidirectional Long Short-Term Memory Networks(Att-BLSTM) to capture the most important se-mantic information in a sentence. The experimental results on the SemEval-2010 relation classiﬁcation task show that our method outperforms most of the existing methods, with only word vectors。<span class="citation">(Zhou et al. 2016)</span></p>
</blockquote>
<p>引入了attention+BiLSTM的结构进行关系分类任务，数据基于SemEval-2010</p>
</div>
<div id="position-indicators" class="section level3">
<h3><span class="header-section-number">1.2.2</span> Position Indicators</h3>
<p>Position Indicators直接使用标签来表示两个entity的位置，例如在SemEval2010_task中:</p>
<p>The <e1> child </e1> was carefully wrapped and bound into the <e2> cradle </e2> by means of a cord
这个句子，就可以使用 <e1>、&lt;1&gt;、<e2>、&lt;2&gt;作为四个Indicators。在训练的时候，直接将这四个标签作为普通的word即可突出两个entity。这个方法也不是该论文首创的，在《Relation classification via recurrent neural network》，已经被提到，其效果如下图所示：</p>
<div class="figure">
<img src="figs/bilstm+att.png" alt="" />
<p class="caption">PI</p>
</div>
</div>
<div id="实验结果" class="section level3">
<h3><span class="header-section-number">1.2.3</span> 实验结果</h3>
<div class="figure">
<img src="figs/BI.png" alt="" />
<p class="caption">BI</p>
</div>
<p>代码：<a href="https://github.com/SeoSangwoo/Attention-Based-BiLSTM-relation-extraction" class="uri">https://github.com/SeoSangwoo/Attention-Based-BiLSTM-relation-extraction</a></p>
</div>
<div id="总结-1" class="section level3">
<h3><span class="header-section-number">1.2.4</span> 总结</h3>
<blockquote>
<p>we propose a new paradigm for the task of entity-relation extraction. We cast the task as a multi-turn question answering problem, i.e., the extraction of entities and relations is transformed to the task of identifying answer spans from the context. This multi-turn
QA formalization comes with several key advantages: ﬁrstly, the question query encodes important information for the entity/relation class we want to identify; secondly, QA provides a natural way of jointly modeling entity and relation; and thirdly, it allows us to exploit the well developed machine reading comprehension (MRC) models.
Experiments on the ACE and the CoNLL04 corpora demonstrate that the proposed paradigm signiﬁcantly outperforms previous best models. We are able to obtain the state-of-the-art results on all of the ACE04, ACE05 and CoNLL04 datasets, increasing the SOTA results on the three datasets to 49.4 (+1.0),60.2 (+0.6) and 68.9 (+1.1), respectively.</p>
</blockquote>
<p>实体和关系的抽取转化为从上下文中识别答案跨度的任务。这种多回合的QA形式化有几个关键的优点：首先，问题查询(query)为想要识别的实体/关系类编码重要信息；其次，QA提供了一种自然的实体和关系联合建模的方式；第三，它能够开发出发展良好的机器阅读理解（MRC）模型。</p>
<p>在ACE和CoNLL04语料库上的实验表明，本文所提出的模型明显优于以前的最佳模型。我们能够获得所有ACE04、ACE05和CoNLL04数据集的最新结果，将这三个数据集的SOTA结果分别增加到49.4（+1.0）、60.2（+0.6）和68.9（+2.1）。</p>
<p>以往的模型主要分为两大类：
- 一类是流水线方法，先用标记模型识别实体，然后用关系抽取模型识别每个实体对之间的关系；pipline
- 另一类是联合方法，通过不同的策略将实体模型和关系模型结合起来，例如约束或参数共享。</p>
</div>
</div>
<div id="joint-entity-recognition-and-relation-extraction-as-a-multi-head-selection-problem" class="section level2">
<h2><span class="header-section-number">1.3</span> Joint entity recognition and relation extraction as a multi-head selection problem</h2>
<p>实体关系联合抽取模型</p>
<blockquote>
<p>Speciﬁcally, we model the entity recognition task using a CRF (Conditional Random Fields) layer and the relation extraction task as a multi-head selection problem (i.e., potentially identify multiple relations for each entity).</p>
</blockquote>
<p>使用CRF(条件随机域)层将实体识别任务和关系提取任务建模为一个多头选择问题。，可能为每个实体标识多个关系)</p>
<p>所谓多头，意思是任何特定的实体都可能涉及到与其他实体的<strong>多种关系</strong></p>
<div id="实体识别模型" class="section level3">
<h3><span class="header-section-number">1.3.1</span> 实体识别模型</h3>
<p>模型的基本层如下图1所示:
<img src="figs/joint.png" alt="joint" />
(i)embedding层，
(ii)双向序列LSTM (BiLSTM)层，
(iii) CRF层，
(iv) sigmoid评分层。</p>
<ul>
<li><p>Embedding层</p></li>
<li><p>输入：句子的token（单词</p></li>
<li><p>输出：词向量
BiLSTM层能够为每个通过RNN结构合并上下文的单词提取更复杂的表示。
然后CRF和sigmoid层就能够生成这两个任务的输出。</p></li>
<li><p>每个token的输出(例如,史密斯)是双重的:
(i)一个实体识别标签(如I-PER,表示命名实体的类型)和
(ii)一组元组组成的头标记实体和它们之间的关系的类型(例如,{(中心工作),(住在亚特兰大)})。</p></li>
<li><p>由于假设了基于标记的编码，所以只将实体的最后一个标记作为另一个标记的头部，从而消除了冗余关系。例如，有一个关于实体约翰·史密斯和疾病控制中心之间工作关系。我们只连接Smith和Center，而不连接实体的所有令牌。同样，对于没有关系的情况，引入N标签，并预测令牌本身为头部。</p></li>
</ul>
</div>
<div id="多头关系抽取模型" class="section level3">
<h3><span class="header-section-number">1.3.2</span> 多头关系抽取模型</h3>
<ul>
<li>将关系提取任务描述为一个多头选择问题(Zhang et al.， 2017;(Bekoulis et al.， 2018)。</li>
<li>在一般公式中，每个令牌wi可以有多个头(即，与其他令牌的多个关系)。</li>
<li>预测元组(yi, c_i)其中yi是正面的向量，而c_i是每个令牌wi对应关系的向量。这与之前的依赖分析方法的标准头选择不同(Zhang et al.， 2017)，因为</li>
<li>(i)它被扩展为预测多个头，</li>
<li>(ii)头的决策和关系是共同做出的(即，而不是先预测正面，然后在下一步使用额外的分类器来预测关系)。</li>
</ul>
<p>输入：给定一个令牌序列w和一组关系标签R作为输入，
目标：我们的目标是识别每个令牌的wi, i{0，…， n}最可能正面的向量y i 和最可能对应关系标签r i的向量
得分（给定一个标签rk，我们计算令牌wi和wj之间的分数如下:</p>
<p><span class="math display">\[s^{(r)}\left(z_{j}, z_{i}, r_{k}\right)=V^{(r)} f\left(U^{(r)} z_{j}+W^{(r)} z_{i}+b^{(r)}\right) \quad \operatorname{Pr}\left(\text {head}=w_{j}, \text { label }=r_{k} | w_{i}\right)=\sigma\left(s^{(r)}\left(z_{j}, z_{i}, r_{k}\right)\right)\]</span>
交叉损失函数</p>
<p><span class="math display">\[\mathcal{L}_{\mathrm{rel}}=\sum_{i=0}^{n} \sum_{j=0}^{m}-\log \operatorname{Pr}\left(\text {head}=y_{i, j}, \text {relation}=r_{i, j} | w_{i}\right)\]</span></p>
</div>
<div id="代码数据" class="section level3">
<h3><span class="header-section-number">1.3.3</span> 代码数据</h3>
<p>github传送门：<a href="https://github.com/bekou/multihead_joint_entity_relation_extraction" class="uri">https://github.com/bekou/multihead_joint_entity_relation_extraction</a></p>
</div>
</div>
<div id="adversarial-training-for-multi-context-joint-entity-and-relation-extraction" class="section level2">
<h2><span class="header-section-number">1.4</span> Adversarial training for multi-context joint entity and relation extraction</h2>
<p>抗多任务学习用于文本分类</p>
<blockquote>
<p>Adversarial training (AT) is a regularizationmethod that can be used to improve the robustness of neural network methods by addingsmall perturbations in the training data. We show how to use AT for the tasks of entity recognition and relation extraction. In particular, we demonstrate that applying AT to a general purpose baseline model for jointly extracting entities and relations, allows improving the state-of-the-art effectiveness on several datasets in different contexts (i.e., news,biomedical, and real estate data) and for different languages (English and Dutch).<span class="citation">(Bekoulis et al. 2018)</span></p>
</blockquote>
<p>神经网络模型因为学习共享层用于捕获任务共有的和与任务相关的特征而在mutil-task任务中表现出很不错的性能。但是现有大多数方法在提取特征时，都因为共享特征中含有task-specific特征或者其他任务的噪声而受到影响。本文<strong>将AT作为联合提取任务的训练过程的扩展</strong>缓解了共享特征空间和特定任务特征空间相互干扰的问题，作者在16个任务上进行实验证明其模型的有效性，并且实验结果表明模型的共享特征学习到的知识可以很好地用在新任务上。</p>
<div id="相关工作" class="section level3">
<h3><span class="header-section-number">1.4.1</span> 相关工作</h3>
<blockquote>
<p>Joint entity and relation extraction: Joint models (Li and Ji, 2014; Miwa and Sasaki, 2014)that are based on manually extracted features have been proposed for performing both the named entity recognition (NER) and relation extraction subtasks at once. These methods rely on the availability of NLP tools (e.g., POS taggers) or manually designed features leading to additional complexity. Neural network methods have been exploited to overcome this feature design issue and usually involve RNNs and CNNs <span class="citation">(Bekoulis et al. 2018)</span></p>
</blockquote>
<p>联合实体和关系提取:</p>
<ul>
<li><p>联合模型(Li and Ji, 2014;Miwa和Sasaki(2014)提出了一种基于手动提取特征的方法，用于同时执行命名实体识别(NER)和关系提取子任务。</p>
<ul>
<li>缺点：这些方法依赖于NLP工具的可用性(例如，POS标记器)或手动设计的特性，从而导致额外的复杂性。</li>
</ul></li>
<li><p>神经网络方法已经被用来克服这一特征设计问题，通常涉及到RNNs和CNNs (Miwa和Bansal，2016; Zheng et al., 2017).)</p></li>
</ul>
<p>实体识别和关系抽取的目标是从非结构化的文本中发现实体mention的关系结构，它对知识库的构建使用和问答等任务都很重要，它是信息抽取的核心问题。</p>
<p>现有的方法整体来说有两种：<strong>把实体识别和关系抽取看作两个分开的任务的pipline模型、联合模型</strong>，它们都存在着缺陷。</p>
<p>现有模型的不足：</p>
<p><strong>pipline模型</strong>：错误会在不同组件之间传播，造成错误的累积；关系抽取只是利用了NER任务的结果，造成一个任务中可能对其他任务有用的信息没有被用到。</p>
<p><strong>联合模型</strong>：有的需要人工特征，虽然利用神经网络已经可以不人工选特征了，但是会依赖于很多NLP工具，如pos标注、依存分析；单个实体的多个关系抽取还存在问题。</p>
<p>本文要介绍的联合模型能一块执行实体识别和关系抽取两个任务，同时能够解决多关系问题，并且不依赖其他的NLP工具，不需要人工设置的特征。</p>
</div>
<div id="创新点" class="section level3">
<h3><span class="header-section-number">1.4.2</span> 创新点</h3>
<ul>
<li><p>将原来的single head selection拓展为预测多个头；</p></li>
<li><p>对于头和关系的决策是一块完成的，而不是先预测头，然后在下一步用关系分类器预测关系；</p></li>
<li><p>对抗训练；</p></li>
</ul>
<p><strong>baseline模型</strong></p>
<blockquote>
<p>We use character level embeddings to implicitly capture morphological features (e.g.,preﬁxes and sufﬁxes), representing each character by a vector (embedding). The character embedings are fed to a bidirectional LSTM (BiLSTM)to obtain the character-based representation of the word. We also use pre-trained word embeddings.
Word and character embeddings are concatenated to form the ﬁnal token representation, which is then fed to a BiLSTM layer to extract sequential information.For the NER task, <strong>we adopt the BIO (Beginning, Inside, Outside) encoding scheme.</strong> <span class="citation">(Bekoulis et al. 2018)</span></p>
</blockquote>
<ul>
<li><p>embedding layer；</p></li>
<li><p>Bilstm layer</p></li>
<li><p>a CRF layer and (iv) a relation extraction layer. In AT, we compute the worst-case perturbations η of the input embeddings.</p></li>
<li><p>在词级别的向量上加入了字符级的信息，这样的embedding可以捕捉如前缀后缀这样的形态特征，这样的形态学特征在英语、德语这类语言的实体识别任务中效果有显著的提升。先用skip-gram word2vec模型预训练得到的词向量表把每个词映射为一个词向量，然后把每个词中字母用一个向量表示，把一个词中所包含的字母的向量送入BiLSTM中，把前向和后向两个最终状态和词向量进行拼接，得到词的embedding。</p></li>
<li><p>经典的BiLSTM模型，把句子中所包含的词的embedding输入其中，然后将前向和后向每个对应位置的hidden state拼接起来得到新的编码序列</p></li>
<li><p>采用BIO标注策略，使用CRF引入标签之间的依赖关系。</p></li>
</ul>
<p>这个就是baseline模型，也就是上一篇文章(3,4这两篇文章是一个实验室发的，4在3的基础上增加了AT)</p>
<div class="figure">
<img src="figs/AT.png" alt="" />
<p class="caption">AT</p>
</div>
</div>
<div id="at" class="section level3">
<h3><span class="header-section-number">1.4.3</span> AT</h3>
<blockquote>
<p>we generate examples which are variations of the original ones by adding some noise at the level of the concatenated word representation (Miyato et al., 2017). This is similar to the concept introduced by Goodfellow et al. (2015) to improve the robustness of image recognition classiﬁers. We generate an adversarial example by adding the worst-case perturbation ηadv to the original embedding w that maximizes the loss function:<span class="citation">(Bekoulis et al. 2018)</span></p>
</blockquote>
<p>AT被认为是一种规则的方法，但它不像worddroup那样引入随机的噪声，AT生成的扰动是容易被模型错误分类的例子的变形。</p>
<blockquote>
<p>抗训练的思路，就是在输入上进行梯度上升(增大loss)，在参数上进行梯度下降(减小loss)。由于输入会进行embedding lookup，所以实际的做法是在embedding table上进行梯度上升。<a href="https://zhuanlan.zhihu.com/p/103593948">知乎专栏</a></p>
</blockquote>
<p>通过在原来的embedding上加入最坏的扰动使得损失函数最大，来得到对抗样例，直接想到的公式如下:</p>
<p><span class="math display">\[\eta_{a d v}=\underset{\|\eta\| \leq \epsilon}{\operatorname{argmax}} \mathcal{L}_{\mathrm{JOINT}}(w+\eta ; \hat{\theta})\]</span></p>
<p>这个公式在神经网络中难以处理，因此采用近似方法</p>
<p><span class="math display">\[\begin{array}{l}
n_{a d v}=\epsilon g /\|g\| \\
g=\nabla_{w} \iota_{J O I N T}(w ; \hat{\theta})
\end{array}\]</span></p>
</div>
<div id="实验结果-1" class="section level3">
<h3><span class="header-section-number">1.4.4</span> 实验结果</h3>
<div class="figure">
<img src="figs/ATRE.png" alt="" />
<p class="caption">ATRE</p>
</div>
</div>
<div id="代码数据-1" class="section level3">
<h3><span class="header-section-number">1.4.5</span> 代码数据</h3>
<p>github传送门：<a href="https://github.com/bekou/multihead_joint_entity_relation_extraction" class="uri">https://github.com/bekou/multihead_joint_entity_relation_extraction</a></p>
</div>
</div>
<div id="entity-relation-extraction-as-multi-turn-question-answering" class="section level2">
<h2><span class="header-section-number">1.5</span> Entity-Relation Extraction as Multi-turn Question Answering</h2>
<p>这个篇文章的创新点在于其<strong>将实体关系联合抽取的任务当作一个多轮问答类问题来处理</strong>，即每种实体和每种关系都用一个问答模板进行刻画，从而这些实体和关系可以通过回答这些模板化的问题来从上下文中进行抽取。</p>
<blockquote>
<p>We cast the task as a multi-turn question answering problem, i.e., the extraction of entities and relations is transformed to the task of identifying answer spans from the context. <span class="citation">(Li et al. 2019)</span></p>
</blockquote>
<ul>
<li>将关系抽取任务顶一个<strong>多轮问答</strong>任务：每个实体类型和关系类型由问答模板表征，实体和关系通过回答模板问题提取。答案是文本跨度（textspans），使用现在标准的机器阅读理解（MRC）框架提取：预测给定上下文时的答案跨度。</li>
</ul>
<blockquote>
<p>ﬁrstly, the question query encodes important information for the entity/relation class we want to identify;
secondly, QA provides a natural way of jointly modeling entity and relation;
and thirdly, it allows us to exploit the well developed machine reading comprehension (MRC) models.<span class="citation">(Li et al. 2019)</span></p>
</blockquote>
<p>这种多转QA形式化具有几个关键优势：</p>
<ul>
<li>首先，问题查询为我们想要识别的实体/关系类编码重要信息;</li>
<li>其次，质量保证提供了一种自然的实体和关系建模方式;</li>
<li>第三，它允许我们利用完善的机器阅读理解（MRC）模型。</li>
</ul>
<div id="头实体抽取阶段和关系和尾部抽取阶段" class="section level3">
<h3><span class="header-section-number">1.5.1</span> 头实体抽取阶段和关系和尾部抽取阶段</h3>
<p>首先确定目标实体 e1
之后根据目标实体和候选关系类别进行提问
这样的处理方法主要有如下几个优点：</p>
<ul>
<li><p>能够很好地捕捉标签的层次依赖性。即随着每一轮问答的进行，我们有序的获得所需要的实体，这与多回合填充式对话系统类似问题的编码能够整合对关系分类任务重要的一些先验信息，这些信息可以潜在地解决了现有关系抽取模型难以解决的问题，如远距离实体对，或是关系重叠问题。</p></li>
<li><p>QA任务提供了一种很自然的方式来融合实体抽取和关系抽取任务，因为 QA 任务对于没有答案的问题可以返回 None，则对于不存在相应关系的问题，如果返回的不是 None，则可以同时确定实体和关系</p></li>
</ul>
<div class="figure">
<img src="figs/weicode.png" alt="" />
<p class="caption">伪代码</p>
</div>
<p>将实体关系抽取任务转化为多轮问答任务的算法如上所示，整个算法分如下几个部分：</p>
<ul>
<li><p><strong>头实体抽取(line 4 - 9)</strong>：由于每一轮多轮对话都需要一个头实体来作为trigger，因此需要事先抽取句子中所有的头实体，而抽取实体的过程可以看作一个抽取 entity_question 答案的过程。所有 entity_question 都存放在 EntityQuesTemplates 中，每一种 entity_question 都对应一类实体的抽取。</p></li>
<li><p><strong>关系与尾实体抽取(line 10 - 24)</strong>：ChainOfRelTemplates
定义了一个关系序列，我们需要根据这个关系序列来进行多轮问答。同时，它也定义了每种关系的模板，为了生成对应的问题（第14行），我们要在模板槽（slot）中插入之前抽取的实体。然后，关系 REL 和尾实体 e 就能通过回答问题同时被抽取出来。如果回答是 None，就说明没有答案，即只有同时抽出头实体，以及头实体存在对应的关系和尾实体被抽出时，才算是成功抽出一个满足条件的三元组了。</p></li>
</ul>
<p>我们知道现阶段常见的 MRC 模型都是通过指针网络的方式，仅预测答案在 Context 中的开始和结束位置，仅适用于单答案的情况。但对于实体识别任务，在一段 Context 中可能有多个答案，所以这种方法并不合适。作者的做法是将其当作以问题为基础的序列标注问题，或者说将 2 个 N-class 分类任务转换成 N 个 5-class 分类任务，其中 N 为句子长度。</p>
<p>作者将 BERT 作为 baseline。训练时，损失函数为两个子任务的叠加，即：</p>
<p><span class="math display">\[L=(1-\lambda) L\left(\text {head}_{e} \text {ntity}\right)+\lambda L\left(\text {tail}_{e} \text {ntity}, \text {rel}\right)\]</span>
为了进一步优化模型性能，还采用了强化学习的方法来进一步优化，</p>
<p>数据集</p>
<p>ACE04, ACE05 and CoNLL04</p>
<p>这部分的数据和代码没有找到</p>
</div>
</div>
<div id="基于dgcnn和概率图的轻量级信息抽取模型" class="section level2">
<h2><span class="header-section-number">1.6</span> 基于DGCNN和概率图的轻量级信息抽取模型</h2>
<p>这个是苏神的一个比赛模型<span class="citation">(Su 2019)</span></p>
<p><a href="https://kexue.fm/archives/6671">科学空间</a></p>
<p>百度的比赛数据集：<a href="http://ai.baidu.com/broad/introduction" class="uri">http://ai.baidu.com/broad/introduction</a></p>
<p>这个是苏神开源的代码：<a href="https://github.com/bojone/kg-2019" class="uri">https://github.com/bojone/kg-2019</a></p>
</div>
<div id="参考文献" class="section level2 unnumbered">
<h2>参考文献</h2>
<div id="refs" class="references">
<div id="ref-bekoulis-etal-2018-adversarial">
<p>Bekoulis, Giannis, Johannes Deleu, Thomas Demeester, and Chris Develder. 2018. “Adversarial Training for Multi-Context Joint Entity and Relation Extraction.” In <em>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</em>, 2830–6. Brussels, Belgium: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/D18-1307">https://doi.org/10.18653/v1/D18-1307</a>.</p>
</div>
<div id="ref-QA">
<p>Li, Xiaoya, Fan Yin, Zijun Sun, Xiayu Li, Arianna Yuan, Duo Chai, Mingxin Zhou, and Jiwei Li. 2019. “Entity-Relation Extraction as Multi-Turn Question Answering,” May.</p>
</div>
<div id="ref-jianlin2019bdkgf">
<p>Su, Jianlin. 2019. “A Hierarchical Relation Extraction Model with Pointer-Tagging Hybrid Structure.” https://github.com/bojone/kg-2019; GitHub.</p>
</div>
<div id="ref-CNN-RELEATION">
<p>Zeng, Daojian. 2014. “Relation Classiﬁcation via Convolutional Deep Neural Network.” paper. 2014.</p>
</div>
<div id="ref-zhou-etal-2016-attention">
<p>Zhou, Peng, Wei Shi, Jun Tian, Zhenyu Qi, Bingchen Li, Hongwei Hao, and Bo Xu. 2016. “Attention-Based Bidirectional Long Short-Term Memory Networks for Relation Classification.” In <em>Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</em>, 207–12. Berlin, Germany: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/P16-2034">https://doi.org/10.18653/v1/P16-2034</a>.</p>
</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>


    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"search": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
