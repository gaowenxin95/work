<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>200604文献阅读</title>
  <meta name="description" content="200604文献阅读" />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="200604文献阅读" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="200604文献阅读" />
  
  
  

<meta name="author" content="高文欣" />


<meta name="date" content="2020-06-05" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  


<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="libs/pagedtable-1.1/js/pagedtable.js"></script>



</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path=""><a href="#文献整理"><i class="fa fa-check"></i><b>1</b> 文献整理</a><ul>
<li class="chapter" data-level="1.1" data-path=""><a href="#relation-classiﬁcation-via-convolutional-deep-neural-network"><i class="fa fa-check"></i><b>1.1</b> Relation Classiﬁcation via Convolutional Deep Neural Network</a><ul>
<li class="chapter" data-level="1.1.1" data-path=""><a href="#方法"><i class="fa fa-check"></i><b>1.1.1</b> 方法</a></li>
<li class="chapter" data-level="1.1.2" data-path=""><a href="#参数"><i class="fa fa-check"></i><b>1.1.2</b> 参数</a></li>
<li class="chapter" data-level="1.1.3" data-path=""><a href="#结果"><i class="fa fa-check"></i><b>1.1.3</b> 结果</a></li>
<li class="chapter" data-level="1.1.4" data-path=""><a href="#总结"><i class="fa fa-check"></i><b>1.1.4</b> 总结</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path=""><a href="#attention-based-bidirectional-long-short-term-memory-networks-for-relation-classiﬁcation"><i class="fa fa-check"></i><b>1.2</b> Attention-Based Bidirectional Long Short-Term Memory Networks for Relation Classiﬁcation</a><ul>
<li class="chapter" data-level="1.2.1" data-path=""><a href="#方法-1"><i class="fa fa-check"></i><b>1.2.1</b> 方法</a></li>
<li class="chapter" data-level="1.2.2" data-path=""><a href="#position-indicators"><i class="fa fa-check"></i><b>1.2.2</b> Position Indicators</a></li>
<li class="chapter" data-level="1.2.3" data-path=""><a href="#实验结果"><i class="fa fa-check"></i><b>1.2.3</b> 实验结果</a></li>
</ul></li>
<li class="chapter" data-level="" data-path=""><a href="#参考文献"><i class="fa fa-check"></i>参考文献</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">200604文献阅读</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title">200604文献阅读</h1>
<p class="author"><em>高文欣</em></p>
<p class="date"><em>2020-06-05</em></p>
</div>
<div id="文献整理" class="section level1">
<h1><span class="header-section-number">1</span> 文献整理</h1>
<blockquote>
<p>信息抽取的定义为：从自然语言文本中抽取指定类型的实体、关系、事件等事实信息，并形成结构化数据输出的文本处理技术。信息抽取是从文本数据中抽取特定信息的一种技术。文本数据是由一些具体的单位构成的，例如句子、段落、篇章，文本信息正是由一些小的具体的单位构成的，例如字、词、词组、句子、段落或是这些具体的单位的组合。抽取文本数据中的名词短语、人名、地名等都是文本信息抽取，当然，文本信息抽取技术所抽取的信息可以是各种类型的信息。</p>
</blockquote>
<div id="relation-classiﬁcation-via-convolutional-deep-neural-network" class="section level2">
<h2><span class="header-section-number">1.1</span> Relation Classiﬁcation via Convolutional Deep Neural Network</h2>
<div id="方法" class="section level3">
<h3><span class="header-section-number">1.1.1</span> 方法</h3>
<blockquote>
<p>In this paper, we exploit a convolutional deep neural network(DNN) to extract lexical and sentence level features. Our method takes all of the word tokens as input without complicated pre-processing. First, the word tokens are transformed to vectors by looking up word embeddings1. Then, lexical level features are extracted according to the given nouns. Meanwhile, sentence level features are learned using a convolutional approach. These two level features are concatenated to form the ﬁnal extracted feature vector. Finally, the features are fed into a softmax classiﬁer to predict the relationship between two marked nouns. <span class="citation">(Zeng 2014)</span></p>
</blockquote>
<p>利用卷积深度神经网络（DNN）来提取<strong>词汇</strong>和<strong>句子级别</strong>的特征。</p>
<ul>
<li>预训练好的wordembedding</li>
<li>senstence level提取特征</li>
</ul>
<p>连接这两个级别的特征以形成最终提取的特征向量。最后，将这些特征输入softmax分类器以预测两个标记名词之间的关系。具体如下</p>
<ul>
<li>Word Representation</li>
</ul>
<p>使用预训练好的word embedding作为Word Representation。</p>
<ul>
<li>Lexical Level Features</li>
</ul>
<p>使用通用词嵌入作为基本特征的来源。选择标记名词的嵌入和上下文标记。所有这些功能都连接到词汇级别特征向量。从五个词法层面对句子进行特征提取，来使得我们的模型更加的有偏重性。</p>
<ul>
<li>Sentence Level Features</li>
</ul>
<p>词嵌入技术已经能很好的表达词语之间的相关性。但是不能很好的捕捉远距离的词汇之间的关系，不能让计算机对于一个很长的句子表达有正确的理解。因此我们在句子级别的特征提取中使用卷积神经网络，希望能够结合所有的局部特征、提取句子中远距离的语法信息，最后生成我们的句子级别的特征向量。</p>
<p>本文将输入CNN的token进一步细分为Word Features (WF)和 Position Features
(PF)，其中WF通过设置窗口来在原始单词组成的捕捉句子中某一词语局部的上下文信息，实验决定3是最优窗口大小。</p>
<p>本文还引入了PF，这个是句子中的词语和目标词之间的左右相对距离：</p>
<ul>
<li>CNN</li>
</ul>
<p>前面提取到的都是局部特征，通过CNN提取更加长更加全面的特征。这里的CNN只是简单的<strong>两个隐层</strong>的CNN，使用tanh作为非线性变换函数。</p>
<ul>
<li>softmax分类</li>
</ul>
<p>将CNN输出的全局特征与sentence级别的局部词语表示结合作为输入：f=[l,g]，输出的是一个向量，指明每个分类的概率大小。</p>
</div>
<div id="参数" class="section level3">
<h3><span class="header-section-number">1.1.2</span> 参数</h3>
<div class="figure">
<img src="figs/cnn-para.png" alt="cnn-para" />
<p class="caption">cnn-para</p>
</div>
</div>
<div id="结果" class="section level3">
<h3><span class="header-section-number">1.1.3</span> 结果</h3>
<p>评价指标:F1</p>
<div class="figure">
<img src="figs/CNN-RE.png" alt="cnn-re" />
<p class="caption">cnn-re</p>
</div>
</div>
<div id="总结" class="section level3">
<h3><span class="header-section-number">1.1.4</span> 总结</h3>
<ul>
<li><p>使用词法和句子两大类特征，然后将两大类特征拼接到一起，最后接全连接层+softmax得到分类结果。</p></li>
<li><p>嵌入层使用了预训练的词向量，而不是随机初始化，不过用的不是word2vec，而是(Turian 2010 Word representations: a simple and general method for semi-supervised learning)提供的词嵌入。</p></li>
<li><p>加入了Position Feature，因为CNN更多强调的是局部信息，而Position Feature强调了实体信息。</p></li>
</ul>
<blockquote>
<p>We conduct experiments using the SemEval-2010 Task 8 dataset.<span class="citation">(Zeng 2014)</span></p>
</blockquote>
<p>使用SemEval 2010 Task 8 Dataset的数据集，考虑方向共19种关系</p>
<p>数据&amp;代码见:<a href="https://github.com/FrankWork/conv_relation" class="uri">https://github.com/FrankWork/conv_relation</a></p>
<p>或者这个：<a href="https://blog.csdn.net/herosunly/article/details/90145218" class="uri">https://blog.csdn.net/herosunly/article/details/90145218</a></p>
</div>
</div>
<div id="attention-based-bidirectional-long-short-term-memory-networks-for-relation-classiﬁcation" class="section level2">
<h2><span class="header-section-number">1.2</span> Attention-Based Bidirectional Long Short-Term Memory Networks for Relation Classiﬁcation</h2>
<div id="方法-1" class="section level3">
<h3><span class="header-section-number">1.2.1</span> 方法</h3>
<blockquote>
<p>To tackle these problems,we propose Attention-Based Bidirectional Long Short-Term Memory Networks(Att-BLSTM) to capture the most important se-mantic information in a sentence. The experimental results on the SemEval-2010 relation classiﬁcation task show that our method outperforms most of the existing methods, with only word vectors。<span class="citation">(Zhou et al. 2016)</span></p>
</blockquote>
<p>引入了attention+BiLSTM的结构进行关系分类任务，数据基于SemEval-2010</p>
</div>
<div id="position-indicators" class="section level3">
<h3><span class="header-section-number">1.2.2</span> Position Indicators</h3>
<p>Position Indicators直接使用标签来表示两个entity的位置，例如在SemEval2010_task中:</p>
<p>The <e1> child </e1> was carefully wrapped and bound into the <e2> cradle </e2> by means of a cord
这个句子，就可以使用 <e1>、&lt;1&gt;、<e2>、&lt;2&gt;作为四个Indicators。在训练的时候，直接将这四个标签作为普通的word即可突出两个entity。这个方法也不是该论文首创的，在《Relation classification via recurrent neural network》，已经被提到，其效果如下图所示：</p>
<div class="figure">
<img src="figs/bilstm+att.png" alt="PI" />
<p class="caption">PI</p>
</div>
</div>
<div id="实验结果" class="section level3">
<h3><span class="header-section-number">1.2.3</span> 实验结果</h3>
<div class="figure">
<img src="figs/BI.png" alt="BI" />
<p class="caption">BI</p>
</div>
<p>代码：<a href="https://github.com/SeoSangwoo/Attention-Based-BiLSTM-relation-extraction" class="uri">https://github.com/SeoSangwoo/Attention-Based-BiLSTM-relation-extraction</a></p>
</div>
</div>
<div id="参考文献" class="section level2 unnumbered">
<h2>参考文献</h2>
<div id="refs" class="references">
<div id="ref-CNN-RELEATION">
<p>Zeng, Daojian. 2014. “Relation Classiﬁcation via Convolutional Deep Neural Network.” paper. 2014.</p>
</div>
<div id="ref-zhou-etal-2016-attention">
<p>Zhou, Peng, Wei Shi, Jun Tian, Zhenyu Qi, Bingchen Li, Hongwei Hao, and Bo Xu. 2016. “Attention-Based Bidirectional Long Short-Term Memory Networks for Relation Classification.” In <em>Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</em>, 207–12. Berlin, Germany: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/P16-2034">https://doi.org/10.18653/v1/P16-2034</a>.</p>
</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>


    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"search": false
});
});
</script>

</body>

</html>
